!pip install pyspark

from pyspark import SparkContext
from pyspark.sql import SparkSession

sc = SparkContext.getOrCreate()
spark = SparkSession.builder.appName("my-app").getOrCreate()

# Now you can use the spark variable to create a DataFrame and perform Spark operations


from pyspark.sql.functions import col, isnan, when, count
from pyspark.ml.feature import StandardScaler
from pyspark.ml.clustering import KMeans
from pyspark.ml.clustering import BisectingKMeans
from pyspark.ml.clustering import GaussianMixture
from pyspark.sql.functions import *
from pyspark.sql.types import *

committing change

coomit 2
